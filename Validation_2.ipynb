{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29245b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_paths import DATA, OUTPUT, INTERMEDIATE\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from math import ceil\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes, mark_inset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682dbeb8",
   "metadata": {},
   "source": [
    "### 1. Paths to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20495f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) CONFIG: set your INTERMEDIATE folder and file pairs\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "\n",
    "PAIRS = {\n",
    "    \"Atrato\": dict(\n",
    "        swot=INTERMEDIATE / \"Store/Validation/csv/Atrato/Less_filters/Atrato_reg_bottom_error_simple.csv\",\n",
    "        bath=INTERMEDIATE / \"Store/Binary_Masks/Atrato/Less_filters/Atrato_bathy_reg_bottom_error_simple.csv\",\n",
    "    ),\n",
    "    \"Cape_Fear\": dict(\n",
    "        swot=INTERMEDIATE / \"Store/Validation/csv/Cape_fear/Cape_reg_bottom_error_simple.csv\",\n",
    "        bath=INTERMEDIATE / \"Store/Binary_Masks/Cape_fear/Cape_bathy_reg_bottom_error_simple.csv\",\n",
    "    ),\n",
    "    \"Garonne\": dict(\n",
    "        swot=INTERMEDIATE / \"Store/Validation/csv/Garonne/Garonne_reg_bottom_error_simple.csv\",\n",
    "        bath=INTERMEDIATE / \"Store/Binary_Masks/Garonne/Garonne_bathy_reg_bottom_error_simple.csv\",\n",
    "    ),\n",
    "    \"Pee_Dee\": dict(\n",
    "        swot=INTERMEDIATE / \"Store/Validation/csv/Pee_dee/Pee_dee_reg_bottom_error_simple.csv\",\n",
    "        bath=INTERMEDIATE / \"Store/Binary_Masks/Pee_dee/Pee_bathy_reg_bottom_error_simple.csv\",\n",
    "    ),\n",
    "    \"Po\": dict(\n",
    "        swot=INTERMEDIATE / \"Store/Validation/csv/Po/Po_reg_bottom_error_simple.csv\",\n",
    "        bath=INTERMEDIATE / \"Store/Binary_Masks/Po/Po_bathy_reg_bottom_error_simple.csv\",\n",
    "    ),\n",
    "    \"Sacramento\": dict(\n",
    "        swot=INTERMEDIATE / \"Store/Validation/csv/Sacramento/Sacramento_reg_bottom_error_simple.csv\",\n",
    "        bath=INTERMEDIATE / \"Store/Binary_Masks/Sacramento/Sacramento_bathy_reg_bottom_error_simple.csv\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Save outputs\n",
    "OUT_DIR = INTERMEDIATE / \"Store/Validation/compare_swot_bathy\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "SAVE_PLOTS = True\n",
    "N_BOOT = 2000  # bootstrap replicates for CIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2d775c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_csv(pairs: dict, swot_col: str, bath_col: str) -> dict:\n",
    "    \"\"\"Merge SWOT and Bathymetry CSV files on node_id column\"\"\"\n",
    "    merged_dict = {}\n",
    "\n",
    "    for river, paths in pairs.items():\n",
    "        swot_df = pd.read_csv(paths[\"swot\"], usecols=[\"node_id\", swot_col])\n",
    "        bath_df = pd.read_csv(paths[\"bath\"], usecols=[\"node_id\", bath_col])\n",
    "\n",
    "        merged = pd.merge(\n",
    "            swot_df,\n",
    "            bath_df,\n",
    "            on=\"node_id\",\n",
    "            how=\"inner\",\n",
    "        )\n",
    "\n",
    "        merged = merged.groupby(\"node_id\", as_index=False).first()\n",
    "        merged_dict[river] = merged\n",
    "\n",
    "    return merged_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4beb9a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_rivers = merge_csv(PAIRS, \"slope_swot\", \"slope_bathy\")\n",
    "print(merged_rivers[\"Sacramento\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d684812d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sigfig(x, sig=2):\n",
    "    \"\"\"Format number with given significant figures.\"\"\"\n",
    "    if x == 0 or np.isnan(x):\n",
    "        return \"0\"\n",
    "    return f\"{x:.{sig}g}\"\n",
    "\n",
    "def _resolve_cols(df: pd.DataFrame, swot_col: str, bath_col: str) -> tuple[str, str]:\n",
    "    x_cands = [swot_col, f\"{swot_col}_swot\", f\"{swot_col}_x\"]\n",
    "    y_cands = [bath_col, f\"{bath_col}_bath\", f\"{bath_col}_y\"]\n",
    "    x = next((c for c in x_cands if c in df.columns), None)\n",
    "    y = next((c for c in y_cands if c in df.columns), None)\n",
    "    if x is None or y is None:\n",
    "        non_key = [c for c in df.columns if c != \"node_id\"]\n",
    "        if len(non_key) >= 2:\n",
    "            if x is None: x = non_key[0]\n",
    "            if y is None: y = non_key[1]\n",
    "    if x is None or y is None:\n",
    "        raise KeyError(f\"Could not resolve columns. Have: {df.columns.tolist()}\")\n",
    "    return x, y\n",
    "\n",
    "\n",
    "# 1) GRID OF PANELS\n",
    "def plot_grid_by_river(\n",
    "    merged_dict: dict[str, pd.DataFrame],\n",
    "    swot_col: str,\n",
    "    bath_col: str,\n",
    "    ncols: int = 3,\n",
    "    figsize_per_panel=(4.8, 4.2),\n",
    "    scatter_size: int = 26,\n",
    "    loglog: bool = False\n",
    "):\n",
    "    rivers = [r for r, df in merged_dict.items() if not df.empty]\n",
    "    if not rivers:\n",
    "        print(\"No non-empty rivers to plot.\")\n",
    "        return\n",
    "\n",
    "    nrows = ceil(len(rivers) / ncols)\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows, ncols,\n",
    "        figsize=(figsize_per_panel[0]*ncols, figsize_per_panel[1]*nrows)\n",
    "    )\n",
    "    axes = np.atleast_1d(axes).ravel()\n",
    "\n",
    "    all_x, all_y, resolved = [], [], {}\n",
    "    for river in rivers:\n",
    "        df = merged_dict[river]\n",
    "        xname, yname = _resolve_cols(df, swot_col, bath_col)\n",
    "        d = df[[xname, yname]].dropna()\n",
    "        if loglog:\n",
    "            d = d[(d[xname] > 0) & (d[yname] > 0)]\n",
    "        if d.empty: continue\n",
    "        resolved[river] = (xname, yname, d)\n",
    "        all_x.append(d[xname].astype(float).values)\n",
    "        all_y.append(d[yname].astype(float).values)\n",
    "\n",
    "    all_x = np.concatenate(all_x)\n",
    "    all_y = np.concatenate(all_y)\n",
    "    vmin = np.nanmin([all_x.min(), all_y.min()])\n",
    "    vmax = np.nanmax([all_x.max(), all_y.max()])\n",
    "    pad = 0.02 * (vmax - vmin if vmax > vmin else 1.0)\n",
    "    lims = (vmin - pad, vmax + pad)\n",
    "\n",
    "    for ax, river in zip(axes, rivers):\n",
    "        if river not in resolved:\n",
    "            ax.axis(\"off\"); continue\n",
    "        xname, yname, d = resolved[river]\n",
    "        x, y = d[xname].astype(float).values, d[yname].astype(float).values\n",
    "        n = len(d)\n",
    "        rho_s, p_s = spearmanr(x, y)\n",
    "        r_p, p_p = pearsonr(x, y)\n",
    "\n",
    "        ax.scatter(x, y, s=scatter_size, alpha=0.75, edgecolor=\"k\", linewidth=0.4)\n",
    "        ax.plot(lims, lims, \"--\", linewidth=1, color=\"gray\")\n",
    "\n",
    "        if loglog:\n",
    "            ax.set_xscale(\"log\")\n",
    "            ax.set_yscale(\"log\")\n",
    "\n",
    "        ax.set_xlim(lims)\n",
    "        ax.set_ylim(lims)\n",
    "        ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "        ax.set_title(river, fontsize=11)\n",
    "        ax.set_xlabel(xname)\n",
    "        ax.set_ylabel(yname)\n",
    "\n",
    "        stats_txt = (\n",
    "            f\"ρ={_sigfig(rho_s)}, p={_sigfig(p_s)}\\n\"\n",
    "            f\"r={_sigfig(r_p)}, p={_sigfig(p_p)}\\n\"\n",
    "            f\"n={n}\"\n",
    "        )\n",
    "        ax.legend(\n",
    "            [Line2D([], [], color=\"none\")],\n",
    "            [stats_txt],\n",
    "            loc=\"upper left\",\n",
    "            frameon=True,\n",
    "            handlelength=0,\n",
    "            handletextpad=0,\n",
    "            borderaxespad=0.8,\n",
    "            fontsize=9\n",
    "        )\n",
    "\n",
    "    for ax in axes[len(rivers):]:\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 2) ALL RIVERS TOGETHER\n",
    "def plot_all_rivers_together(\n",
    "    merged_dict: dict[str, pd.DataFrame],\n",
    "    swot_col: str,\n",
    "    bath_col: str,\n",
    "    figsize=(6.5, 5.8),\n",
    "    scatter_size: int = 26,\n",
    "    loglog: bool = False\n",
    "):\n",
    "    records, name_map = [], {}\n",
    "    for river, df in merged_dict.items():\n",
    "        if df.empty: continue\n",
    "        try:\n",
    "            xname, yname = _resolve_cols(df, swot_col, bath_col)\n",
    "        except KeyError: continue\n",
    "        d = df[[xname, yname]].dropna().copy()\n",
    "        if loglog:\n",
    "            d = d[(d[xname] > 0) & (d[yname] > 0)]\n",
    "        if d.empty: continue\n",
    "        d[\"__river__\"] = river\n",
    "        records.append(d)\n",
    "        name_map[river] = (xname, yname)\n",
    "    if not records:\n",
    "        print(\"No data available across rivers.\"); return\n",
    "\n",
    "    D = pd.concat(records, ignore_index=True)\n",
    "    xcol, ycol = list(name_map.values())[0]\n",
    "    x, y = D[xcol].astype(float).values, D[ycol].astype(float).values\n",
    "\n",
    "    rho_s, p_s = spearmanr(x, y)\n",
    "    r_p, p_p = pearsonr(x, y)\n",
    "    total_n = len(D)\n",
    "\n",
    "    vmin = np.nanmin([x.min(), y.min()])\n",
    "    vmax = np.nanmax([x.max(), y.max()])\n",
    "    pad = 0.02 * (vmax - vmin if vmax > vmin else 1.0)\n",
    "    lims = (vmin - pad, vmax + pad)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    rivers = D[\"__river__\"].unique().tolist()\n",
    "    color_map = {r: c for r, c in zip(rivers, plt.rcParams['axes.prop_cycle'].by_key()['color'])}\n",
    "\n",
    "    for river in rivers:\n",
    "        sub = D[D[\"__river__\"] == river]\n",
    "        ax.scatter(sub[xcol], sub[ycol],\n",
    "                   s=scatter_size, alpha=0.75, edgecolor=\"k\", linewidth=0.4,\n",
    "                   label=f\"{river} (n={len(sub)})\",\n",
    "                   c=color_map[river])\n",
    "\n",
    "    ax.plot(lims, lims, \"--\", linewidth=1, color=\"gray\")\n",
    "\n",
    "    if loglog:\n",
    "        ax.set_xscale(\"log\")\n",
    "        ax.set_yscale(\"log\")\n",
    "\n",
    "    ax.set_xlim(lims)\n",
    "    ax.set_ylim(lims)\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "    ax.set_xlabel(xcol)\n",
    "    ax.set_ylabel(ycol)\n",
    "    ax.set_title(\"All rivers\")\n",
    "\n",
    "    stats_txt = (\n",
    "        f\"ρ={_sigfig(rho_s)}, p={_sigfig(p_s)}\\n\"\n",
    "        f\"r={_sigfig(r_p)}, p={_sigfig(p_p)}\\n\"\n",
    "        f\"n={total_n}\"\n",
    "    )\n",
    "    ax.legend(\n",
    "        [Line2D([], [], color=\"none\")],\n",
    "        [stats_txt],\n",
    "        loc=\"upper left\",\n",
    "        frameon=True,\n",
    "        handlelength=0,\n",
    "        handletextpad=0,\n",
    "        borderaxespad=0.8,\n",
    "        fontsize=9\n",
    "    )\n",
    "\n",
    "    # separate legend for rivers\n",
    "    #ax.legend(loc=\"lower right\", frameon=True, fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b99b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid_by_river(merged_rivers, swot_col=\"slope_SWOT\", bath_col=\"slope_bathy\", ncols=3, loglog=False)\n",
    "\n",
    "plot_all_rivers_together(merged_rivers, swot_col=\"slope_SWOT\", bath_col=\"slope_bathy\", loglog=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0bb123",
   "metadata": {},
   "outputs": [],
   "source": [
    "xcol = \"width\"\n",
    "ycol = \"xtrk_dist\"\n",
    "\n",
    "def _clean_numeric(a):\n",
    "    a = pd.to_numeric(a, errors=\"coerce\")\n",
    "    return a.to_numpy()\n",
    "\n",
    "# Manual river → color map\n",
    "river_colors = {\n",
    "    \"Garonne\": \"red\",\n",
    "    \"Pee_Dee\": \"blue\",\n",
    "    \"Po\": \"green\",\n",
    "    \"Sacramento\": \"purple\",\n",
    "    \"Cape_Fear\": \"orange\",\n",
    "    \"Atrato\": \"black\"\n",
    "}\n",
    "\n",
    "# 1) Load all data once to define global bin edges\n",
    "all_x, all_y = [], []\n",
    "per_river = {}\n",
    "for river, files in PAIRS.items():\n",
    "    df = pd.read_csv(files[\"swot\"])\n",
    "    x = _clean_numeric(df[ycol])   # x-axis (xtrk_dist)\n",
    "    y = _clean_numeric(df[xcol])   # y-axis (width)\n",
    "    m = np.isfinite(x) & np.isfinite(y)\n",
    "    x, y = x[m], y[m]\n",
    "    per_river[river] = (x, y)\n",
    "    if x.size and y.size:\n",
    "        all_x.append(x); all_y.append(y)\n",
    "\n",
    "all_x = np.concatenate(all_x)\n",
    "all_y = np.concatenate(all_y)\n",
    "\n",
    "# 2) Define common bin edges\n",
    "xbins = 100\n",
    "ybins = 100\n",
    "xedges = np.linspace(np.nanmin(all_x), np.nanmax(all_x), xbins + 1)\n",
    "yedges = np.linspace(np.nanmin(all_y), np.nanmax(all_y), ybins + 1)\n",
    "\n",
    "# 3) Background heatmap\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "H_all, _, _ = np.histogram2d(all_x, all_y, bins=[xedges, yedges])\n",
    "\n",
    "cmap = plt.cm.viridis.copy()\n",
    "cmap.set_under(\"white\")\n",
    "im = ax.pcolormesh(\n",
    "    xedges, yedges, H_all.T,\n",
    "    norm=mcolors.LogNorm(vmin=1),\n",
    "    cmap=cmap\n",
    ")\n",
    "\n",
    "# 4) Trend lines only (both sides dashed)\n",
    "proxies = []\n",
    "for river, (x, y) in per_river.items():\n",
    "    color = river_colors.get(river, \"black\")  # fallback = black\n",
    "    for mask in (x < 0, x > 0):\n",
    "        xs, ys = x[mask], y[mask]\n",
    "        if xs.size >= 2 and np.unique(xs).size >= 2:\n",
    "            slope, intercept = np.polyfit(xs, ys, 1)\n",
    "            xq_lo, xq_hi = np.nanpercentile(xs, [1, 99])\n",
    "            if xq_hi > xq_lo:\n",
    "                x_fit = np.linspace(xq_lo, xq_hi, 200)\n",
    "                y_fit = slope * x_fit + intercept\n",
    "                ax.plot(x_fit, y_fit, linestyle=\"--\", linewidth=2, color=color)\n",
    "    proxies.append(Line2D([0], [0], color=color, lw=2, label=river))\n",
    "\n",
    "# divider at x=0\n",
    "ax.axvline(0, color=\"k\", lw=1, alpha=0.25)\n",
    "\n",
    "# 5) Colorbar + legend\n",
    "cbar = plt.colorbar(im, ax=ax)\n",
    "cbar.set_label(\"Counts per bin (log scale)\")\n",
    "ax.legend(handles=proxies, title=\"River\", loc=\"upper right\")\n",
    "\n",
    "ax.set_xlabel(ycol)\n",
    "ax.set_ylabel(xcol)\n",
    "ax.set_ylim(0, 1500)\n",
    "ax.set_title(\"Six rivers: background density + per-river split trend lines (dashed)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38af244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_river(PAIRS, river, bins=100, y_max=1500):\n",
    "    \"\"\"One plot for one river: background heatmap + split (x<0 / x>0) dashed trend lines.\"\"\"\n",
    "    df = pd.read_csv(PAIRS[river][\"swot\"])\n",
    "    x = _clean_numeric(df[\"xtrk_dist\"])   # x-axis\n",
    "    y = _clean_numeric(df[\"width\"])       # y-axis\n",
    "    m = np.isfinite(x) & np.isfinite(y)\n",
    "    x, y = x[m], y[m]\n",
    "    if x.size == 0:\n",
    "        raise RuntimeError(f\"No valid data for {river}.\")\n",
    "\n",
    "    # bin edges\n",
    "    xedges = np.linspace(np.nanmin(x), np.nanmax(x), bins + 1)\n",
    "    yedges = np.linspace(np.nanmin(y), np.nanmax(y), bins + 1)\n",
    "\n",
    "    # background heatmap\n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    H, _, _ = np.histogram2d(x, y, bins=[xedges, yedges])\n",
    "\n",
    "    cmap = plt.cm.viridis.copy()\n",
    "    cmap.set_under(\"white\")\n",
    "    im = ax.pcolormesh(\n",
    "        xedges, yedges, H.T,\n",
    "        norm=mcolors.LogNorm(vmin=1),\n",
    "        cmap=cmap\n",
    "    )\n",
    "\n",
    "    # dashed trend lines (x<0 and x>0)\n",
    "    color = river_colors.get(river, \"black\")\n",
    "    for mask in (x < 0, x > 0):\n",
    "        xs, ys = x[mask], y[mask]\n",
    "        if xs.size >= 2 and np.unique(xs).size >= 2:\n",
    "            slope, intercept = np.polyfit(xs, ys, 1)\n",
    "            xq_lo, xq_hi = np.nanpercentile(xs, [1, 99])\n",
    "            if xq_hi > xq_lo:\n",
    "                x_fit = np.linspace(xq_lo, xq_hi, 200)\n",
    "                y_fit = slope * x_fit + intercept\n",
    "                ax.plot(x_fit, y_fit, linestyle=\"--\", linewidth=2, color=color)\n",
    "\n",
    "    # divider at x=0\n",
    "    ax.axvline(0, color=\"k\", lw=1, alpha=0.25)\n",
    "\n",
    "    # colorbar + labels\n",
    "    cbar = plt.colorbar(im, ax=ax)\n",
    "    cbar.set_label(\"Counts per bin (log scale)\")\n",
    "    ax.set_xlabel(\"xtrk_dist\")\n",
    "    ax.set_ylabel(\"width\")\n",
    "    if y_max is not None:\n",
    "        ax.set_ylim(0, y_max)\n",
    "    ax.set_title(f\"{river}: density + split trend lines (dashed)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de4e802",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_single_river(PAIRS, \"Sacramento\", bins=110, y_max=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225d6eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "basins1 = pd.read_csv(OUTPUT / \"Global_22_07_25/B61_huber_reg.csv\")\n",
    "basins2 = pd.read_csv(OUTPUT / \"Global_22_07_25/B62_huber_reg.csv\")\n",
    "basins3 = pd.read_csv(OUTPUT / \"Global_22_07_25/B74_huber_reg.csv\")\n",
    "basins4 = pd.read_csv(OUTPUT / \"Global_22_07_25/B73_huber_reg.csv\")\n",
    "basins5 = pd.read_csv(OUTPUT / \"Global_22_07_25/B23_huber_reg.csv\")\n",
    "basins6 = pd.read_csv(OUTPUT / \"Global_22_07_25/B21_huber_reg.csv\")\n",
    "basins8 = pd.read_csv(OUTPUT / \"Global_22_07_25/B45_huber_reg.csv\")\n",
    "basins9 = pd.read_csv(OUTPUT / \"Global_22_07_25/B34_huber_reg.csv\")\n",
    "basins10 = pd.read_csv(OUTPUT / \"Global_22_07_25/B53_huber_reg.csv\")\n",
    "basins11 = pd.read_csv(OUTPUT / \"Global_22_07_25/B52_huber_reg.csv\")\n",
    "basins12 = pd.read_csv(OUTPUT / \"Global_22_07_25/B13_huber_reg.csv\")\n",
    "basins13 = pd.read_csv(OUTPUT / \"Global_22_07_25/B12_huber_reg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f250436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all into one\n",
    "basins = pd.concat(\n",
    "    [basins1, basins2, basins3, basins4, basins5,\n",
    "     basins6, basins8, basins9, basins10,\n",
    "     basins11, basins12, basins13],\n",
    "    ignore_index=True   # reindex rows 0..N-1\n",
    ")\n",
    "len(basins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e040e25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- columns ---\n",
    "xcol = \"width\"        # y-axis\n",
    "ycol = \"xtrk_dist\"    # x-axis\n",
    "\n",
    "def _clean_numeric(a):\n",
    "    return pd.to_numeric(a, errors=\"coerce\").to_numpy()\n",
    "\n",
    "# basins = pd.read_csv(...)\n",
    "\n",
    "x = _clean_numeric(basins[ycol])\n",
    "y = _clean_numeric(basins[xcol])\n",
    "m = np.isfinite(x) & np.isfinite(y)\n",
    "x, y = x[m], y[m]\n",
    "\n",
    "# ---- choose how to define the line's span ----\n",
    "USE_PERCENTILES = True\n",
    "PCT_LO, PCT_HI = 1, 99   # robust endpoints if True\n",
    "\n",
    "def span(xs):\n",
    "    \"\"\"Return (x_start, x_end) for the fitted line span.\"\"\"\n",
    "    if USE_PERCENTILES:\n",
    "        lo, hi = np.nanpercentile(xs, [PCT_LO, PCT_HI])\n",
    "    else:\n",
    "        lo, hi = np.nanmin(xs), np.nanmax(xs)\n",
    "    return float(lo), float(hi)\n",
    "\n",
    "# --- background density ---\n",
    "xbins = 100\n",
    "ybins = 100\n",
    "xedges = np.linspace(np.nanmin(x), np.nanmax(x), xbins + 1)\n",
    "yedges = np.linspace(np.nanmin(y), np.nanmax(y), ybins + 1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "H, _, _ = np.histogram2d(x, y, bins=[xedges, yedges])\n",
    "cmap = plt.cm.viridis.copy()\n",
    "cmap.set_under(\"white\")\n",
    "im = ax.pcolormesh(xedges, yedges, H.T, norm=mcolors.LogNorm(vmin=1), cmap=cmap)\n",
    "\n",
    "# --- trend lines + compute increment (Δwidth) from start to end of each fitted line ---\n",
    "left_info  = \"x < 0\\n\"\n",
    "right_info = \"x > 0\\n\"\n",
    "\n",
    "for side_label, mask, box in ((\"x<0\", x < 0, \"left\"), (\"x>0\", x > 0, \"right\")):\n",
    "    xs, ys = x[mask], y[mask]\n",
    "    if xs.size >= 2 and np.unique(xs).size >= 2:\n",
    "        # fit y = m x + b\n",
    "        m_hat, b_hat = np.polyfit(xs, ys, 1)\n",
    "        x0, x1 = span(xs)\n",
    "        if x1 > x0:\n",
    "            # draw line\n",
    "            x_fit = np.linspace(x0, x1, 200)\n",
    "            y_fit = m_hat * x_fit + b_hat\n",
    "            ax.plot(x_fit, y_fit, linestyle=\"--\", linewidth=2, color=\"red\")\n",
    "\n",
    "            # increment from start to end of the fitted span\n",
    "            y_start = m_hat * x0 + b_hat\n",
    "            y_end   = m_hat * x1 + b_hat\n",
    "            dwidth  = y_end - y_start   # <-- THIS is the increment you want\n",
    "\n",
    "            # add to inset text\n",
    "            line = (\n",
    "                f\"m = {m_hat:+.3f}\\n\"\n",
    "                f\"span: [{x0:.0f}, {x1:.0f}]  → Δwidth = {dwidth:+.1f}\"\n",
    "            )\n",
    "            if box == \"left\":\n",
    "                left_info += line\n",
    "            else:\n",
    "                right_info += line\n",
    "    else:\n",
    "        if box == \"left\":\n",
    "            left_info += \"(insufficient data)\"\n",
    "        else:\n",
    "            right_info += \"(insufficient data)\"\n",
    "\n",
    "# divider at x=0\n",
    "ax.axvline(0, color=\"k\", lw=1, alpha=0.25)\n",
    "\n",
    "# insets\n",
    "left_box = AnchoredText(\n",
    "    left_info, loc=\"upper left\", prop=dict(size=9),\n",
    "    frameon=True, bbox_to_anchor=(0.01, 0.80),   # ⬅ y=0.80 instead of 0.99\n",
    "    bbox_transform=ax.transAxes, borderpad=0.4\n",
    ")\n",
    "left_box.patch.set_boxstyle(\"round,pad=0.3\")\n",
    "left_box.patch.set_alpha(0.85)\n",
    "ax.add_artist(left_box)\n",
    "\n",
    "# right box: lower right\n",
    "right_box = AnchoredText(\n",
    "    right_info, loc=\"lower right\", prop=dict(size=9),\n",
    "    frameon=True, bbox_to_anchor=(0.99, 0.20),   # ⬅ y=0.20 moves it to bottom\n",
    "    bbox_transform=ax.transAxes, borderpad=0.4\n",
    ")\n",
    "right_box.patch.set_boxstyle(\"round,pad=0.3\")\n",
    "right_box.patch.set_alpha(0.85)\n",
    "ax.add_artist(right_box)\n",
    "\n",
    "# labels & colorbar\n",
    "cbar = plt.colorbar(im, ax=ax)\n",
    "cbar.set_label(\"Counts per bin (log scale)\")\n",
    "ax.set_xlabel(ycol); ax.set_ylabel(xcol)\n",
    "ax.set_ylim(0, 7000); ax.set_xlim(-70000, 70000)\n",
    "ax.set_title(\"All basins: density + split trend lines\\nInsets show slope and Δwidth over the fitted span\")\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2752c4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- helpers ---------\n",
    "def _clean_numeric(a):\n",
    "    return pd.to_numeric(a, errors=\"coerce\").to_numpy()\n",
    "\n",
    "def _fit_line(xs, ys):\n",
    "    \"\"\"Return (slope, intercept, x_lo, x_hi) using robust 1–99% x-range; None if not fit.\"\"\"\n",
    "    if xs.size < 2 or np.unique(xs).size < 2:\n",
    "        return None\n",
    "    slope, intercept = np.polyfit(xs, ys, 1)\n",
    "    x_lo, x_hi = np.nanpercentile(xs, [1, 99])\n",
    "    if not (x_hi > x_lo):\n",
    "        x_lo, x_hi = float(np.nanmin(xs)), float(np.nanmax(xs))\n",
    "    return slope, intercept, float(x_lo), float(x_hi)\n",
    "\n",
    "# --------- main function ---------\n",
    "def plot_scatter_node_with_inset(\n",
    "    PAIRS, river, node_id=None,\n",
    "    y_max=1500, x_limits=None,\n",
    "    pct_window=(5, 95),                   # zoom window percentiles for main data\n",
    "    inset_size=(\"38%\", \"38%\"),            # width/height of inset\n",
    "    inset_loc=\"upper right\",              # 'upper right' | 'upper left' | 'lower right' | 'lower left'\n",
    "    inset_anchor=None,                    # if set: (x, y, w, h) in axes coords\n",
    "    connectors=(2, 4),                    # corners used by mark_inset\n",
    "    scatter_kwargs=None                   # override scatter styling\n",
    "):\n",
    "    \"\"\"\n",
    "    Pretty scatter of xtrk_dist (X) vs width (Y) for a river (optionally filtered by node_id),\n",
    "    with a zoomed inset that includes dashed trend lines for x<0 and x>0.\n",
    "    \"\"\"\n",
    "    # --- load & filter ---\n",
    "    df = pd.read_csv(PAIRS[river][\"swot\"])\n",
    "    if node_id is not None:\n",
    "        if isinstance(node_id, (list, tuple, set)):\n",
    "            df = df[df[\"node_id\"].isin(node_id)]\n",
    "        else:\n",
    "            df = df[df[\"node_id\"] == node_id]\n",
    "    if df.empty:\n",
    "        raise RuntimeError(f\"No data for {river}, node_id={node_id}\")\n",
    "\n",
    "    x = _clean_numeric(df[\"xtrk_dist\"])\n",
    "    y = _clean_numeric(df[\"width\"])\n",
    "    m = np.isfinite(x) & np.isfinite(y)\n",
    "    x, y = x[m], y[m]\n",
    "    if x.size == 0:\n",
    "        raise RuntimeError(\"No finite points after cleaning\")\n",
    "\n",
    "    # --- base scatter ---\n",
    "    if scatter_kwargs is None:\n",
    "        scatter_kwargs = dict(s=10, alpha=0.9, c=\"tab:blue\", edgecolor=\"none\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    ax.scatter(x, y, **scatter_kwargs)\n",
    "    ax.axvline(0, color=\"k\", lw=1, alpha=0.9)\n",
    "\n",
    "    ax.set_xlabel(\"xtrk_dist\")\n",
    "    ax.set_ylabel(\"width\")\n",
    "    if y_max is not None:\n",
    "        ax.set_ylim(0, y_max)\n",
    "    if x_limits is not None:\n",
    "        ax.set_xlim(*x_limits)\n",
    "\n",
    "    title_extra = f\" (node_id={node_id})\" if node_id is not None else \"\"\n",
    "    ax.set_title(f\"{river} — {title_extra}\")\n",
    "\n",
    "    # --- compute zoom window from percentiles ---\n",
    "    p_lo, p_hi = pct_window\n",
    "    x_lo, x_hi = np.nanpercentile(x, [p_lo, p_hi])\n",
    "    y_lo, y_hi = np.nanpercentile(y, [p_lo, p_hi])\n",
    "    # small padding\n",
    "    pad_x = 0.03 * (x_hi - x_lo) if x_hi > x_lo else 1.0\n",
    "    pad_y = 0.03 * (y_hi - y_lo) if y_hi > y_lo else 1.0\n",
    "    zx0, zx1 = x_lo - pad_x, x_hi + pad_x\n",
    "    zy0, zy1 = y_lo - pad_y, y_hi + pad_y\n",
    "\n",
    "    # --- inset axes placement ---\n",
    "    if inset_anchor is None:\n",
    "        axins = inset_axes(\n",
    "            ax, width=inset_size[0], height=inset_size[1],\n",
    "            loc=inset_loc, borderpad=1.0\n",
    "        )\n",
    "    else:\n",
    "        axins = inset_axes(\n",
    "            ax, width=inset_size[0], height=inset_size[1],\n",
    "            bbox_to_anchor=inset_anchor, bbox_transform=ax.transAxes,\n",
    "            loc=\"lower left\", borderpad=0.4\n",
    "        )\n",
    "\n",
    "    axins.set_facecolor((1, 1, 1, 0.90))\n",
    "    axins.set_zorder(3)\n",
    "\n",
    "    # --- inset scatter ---\n",
    "    axins.scatter(x, y, s=6, alpha=0.9, c=scatter_kwargs.get(\"c\", \"tab:blue\"), edgecolor=\"none\")\n",
    "    axins.set_xlim(zx0, zx1)\n",
    "    axins.set_ylim(zy0, zy1)\n",
    "    axins.axvline(0, color=\"k\", lw=1, alpha=0.9)\n",
    "    axins.set_xlabel(\"xtrk_dist\", fontsize=8)\n",
    "    axins.set_ylabel(\"width\", fontsize=8)\n",
    "    axins.tick_params(axis=\"both\", labelsize=7)\n",
    "    axins.set_title(\"zoom + trends\", fontsize=8, pad=2)\n",
    "\n",
    "    # --- dashed trend lines inside inset ---\n",
    "    for xmask in (x < 0, x > 0):\n",
    "        xs, ys = x[xmask], y[xmask]\n",
    "        fit = _fit_line(xs, ys)\n",
    "        if fit is None:\n",
    "            continue\n",
    "        slope, intercept, xlo_side, xhi_side = fit\n",
    "        lo = max(min(xlo_side, xhi_side), zx0)\n",
    "        hi = min(max(xlo_side, xhi_side), zx1)\n",
    "        if hi > lo:\n",
    "            x_fit = np.linspace(lo, hi, 200)\n",
    "            y_fit = slope * x_fit + intercept\n",
    "            axins.plot(x_fit, y_fit, linestyle=\"--\", linewidth=1.5, color=\"red\")\n",
    "\n",
    "    # --- rectangle connectors on main plot ---\n",
    "    try:\n",
    "        mark_inset(ax, axins, loc1=connectors[0], loc2=connectors[1],\n",
    "                   fc=\"none\", ec=\"crimson\", lw=1.2, alpha=0.2)\n",
    "    except Exception:\n",
    "        import matplotlib.patches as patches\n",
    "        rect = patches.Rectangle((zx0, zy0), zx1 - zx0, zy1 - zy0,\n",
    "                                 fill=False, ec=\"crimson\", lw=1.2, alpha=0.2)\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c2e794",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter_node_with_inset(PAIRS, \"Atrato\", node_id=61100201250351, y_max=600,  pct_window=(2, 100),inset_loc=\"upper center\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d690972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try SciPy for p-values; fall back to pandas if unavailable\n",
    "try:\n",
    "    from scipy.stats import pearsonr, spearmanr\n",
    "    _HAVE_SCIPY = True\n",
    "except Exception:\n",
    "    _HAVE_SCIPY = False\n",
    "\n",
    "# --------- helpers (your originals kept) ---------\n",
    "def _clean_numeric(a):\n",
    "    return pd.to_numeric(a, errors=\"coerce\").to_numpy()\n",
    "\n",
    "def _fit_line(xs, ys):\n",
    "    \"\"\"Return (slope, intercept, x_lo, x_hi) using robust 1–99% x-range; None if not fit.\"\"\"\n",
    "    if xs.size < 2 or np.unique(xs).size < 2:\n",
    "        return None\n",
    "    slope, intercept = np.polyfit(xs, ys, 1)\n",
    "    x_lo, x_hi = np.nanpercentile(xs, [1, 99])\n",
    "    if not (x_hi > x_lo):\n",
    "        x_lo, x_hi = float(np.nanmin(xs)), float(np.nanmax(xs))\n",
    "    return slope, intercept, float(x_lo), float(x_hi)\n",
    "\n",
    "def _corr_stats(xs, ys):\n",
    "    xs = np.asarray(xs); ys = np.asarray(ys)\n",
    "    m = np.isfinite(xs) & np.isfinite(ys)\n",
    "    xs, ys = xs[m], ys[m]\n",
    "    n = xs.size\n",
    "    if n < 3:\n",
    "        return {\"n\": n, \"pearson\": (np.nan, np.nan), \"spearman\": (np.nan, np.nan)}\n",
    "    if _HAVE_SCIPY:\n",
    "        try:\n",
    "            r_p, p_p = pearsonr(xs, ys)\n",
    "        except Exception:\n",
    "            r_p, p_p = (np.nan, np.nan)\n",
    "        try:\n",
    "            r_s, p_s = spearmanr(xs, ys)\n",
    "        except Exception:\n",
    "            r_s, p_s = (np.nan, np.nan)\n",
    "    else:\n",
    "        r_p = pd.Series(xs).corr(pd.Series(ys), method=\"pearson\")\n",
    "        r_s = pd.Series(xs).corr(pd.Series(ys), method=\"spearman\")\n",
    "        p_p = np.nan; p_s = np.nan\n",
    "    return {\"n\": n, \"pearson\": (r_p, p_p), \"spearman\": (r_s, p_s)}\n",
    "\n",
    "# --------- GRID version using your inset pattern ---------\n",
    "def plot_nodes_grid_with_inset(\n",
    "    PAIRS, river,\n",
    "    node_ids=None,                 # iterable of node_ids; if None, sample fraction\n",
    "    sample_frac=0.25,              # fraction of UNIQUE node_id to sample when node_ids is None\n",
    "    sample_seed=42,\n",
    "    max_panels=12,                 # cap grid size\n",
    "    ncols=2,                       # two columns requested\n",
    "    y_max=1500, x_limits=None,\n",
    "    pct_window=(5, 95),            # zoom window percentiles\n",
    "    inset_size=(\"38%\", \"38%\"),     # inset size per panel\n",
    "    inset_loc=\"upper right\",       # placement inside each panel\n",
    "    connectors=(2, 4),             # mark_inset corners\n",
    "    scatter_kwargs=None,           # same style across panels\n",
    "    show_p=False                   # include p-values in text box\n",
    "):\n",
    "    \"\"\"\n",
    "    Grid of scatterplots (xtrk_dist vs width) per node_id (2 columns).\n",
    "    Each panel has a zoomed inset (like your single-plot function) with dashed trend lines,\n",
    "    and a small text box at the upper-left of the MAIN panel showing r and ρ.\n",
    "    \"\"\"\n",
    "    # Load all data for the river\n",
    "    df_all = pd.read_csv(PAIRS[river][\"swot\"])\n",
    "    if df_all.empty:\n",
    "        raise RuntimeError(f\"No data for river={river}\")\n",
    "\n",
    "    # Choose node_ids\n",
    "    if node_ids is None:\n",
    "        unique_nodes = pd.Series(df_all[\"node_id\"].dropna().unique())\n",
    "        if unique_nodes.empty:\n",
    "            raise RuntimeError(\"No node_id values found.\")\n",
    "        rng = np.random.default_rng(sample_seed)\n",
    "        k_target = max(1, int(np.floor(sample_frac * len(unique_nodes))))\n",
    "        k = min(k_target, max_panels)\n",
    "        node_ids = rng.choice(unique_nodes.values, size=k, replace=False)\n",
    "    else:\n",
    "        node_ids = list(dict.fromkeys(node_ids))\n",
    "        if len(node_ids) > max_panels:\n",
    "            node_ids = node_ids[:max_panels]\n",
    "\n",
    "    n = len(node_ids)\n",
    "    if n == 0:\n",
    "        raise RuntimeError(\"No node_ids selected.\")\n",
    "\n",
    "    # Layout\n",
    "    ncols = max(1, ncols)\n",
    "    nrows = int(np.ceil(n / ncols))\n",
    "\n",
    "    if scatter_kwargs is None:\n",
    "        scatter_kwargs = dict(s=10, alpha=0.9, c=\"tab:blue\", edgecolor=\"none\")  # your defaults\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols,\n",
    "                             figsize=(5.2*ncols, 4.2*nrows))\n",
    "    axes = np.atleast_1d(axes).ravel()\n",
    "\n",
    "    last_ax = -1\n",
    "    for i, node in enumerate(node_ids):\n",
    "        ax = axes[i]\n",
    "        dfi = df_all[df_all[\"node_id\"] == node]\n",
    "        if dfi.empty:\n",
    "            ax.set_visible(False); continue\n",
    "\n",
    "        x = _clean_numeric(dfi[\"xtrk_dist\"])\n",
    "        y = _clean_numeric(dfi[\"width\"])\n",
    "        m = np.isfinite(x) & np.isfinite(y)\n",
    "        x, y = x[m], y[m]\n",
    "        if x.size < 3:\n",
    "            ax.set_visible(False); continue\n",
    "\n",
    "        # --- MAIN scatter (same style for all panels) ---\n",
    "        ax.scatter(x, y, **scatter_kwargs)\n",
    "        ax.axvline(0, color=\"k\", lw=1, alpha=0.9)\n",
    "        ax.set_title(f\"node_id = {node}\", fontsize=10)\n",
    "        ax.set_xlabel(\"xtrk_dist\", fontsize=9)\n",
    "        ax.set_ylabel(\"width\", fontsize=9)\n",
    "        if y_max is not None:\n",
    "            ax.set_ylim(0, y_max)\n",
    "        if x_limits is not None:\n",
    "            ax.set_xlim(*x_limits)\n",
    "\n",
    "        # --- Correlations (overall per node) shown as small INSET TEXT (upper-left of main) ---\n",
    "        stats = _corr_stats(x, y)\n",
    "        r,  p_r  = stats[\"pearson\"]\n",
    "        rho, p_rho = stats[\"spearman\"]\n",
    "        if show_p:\n",
    "            txt = (f\"r={r:+.3f} (p={p_r:.1e})\\n\"\n",
    "                   f\"ρ={rho:+.3f} (p={p_rho:.1e})\")\n",
    "        else:\n",
    "            txt = (f\"r={r:+.3f}\\n\"\n",
    "                   f\"ρ={rho:+.3f}\")\n",
    "        ax.text(0.02, 0.98, txt, transform=ax.transAxes, va=\"top\", ha=\"left\",\n",
    "                fontsize=8, color=\"black\",\n",
    "                bbox=dict(facecolor=\"white\", alpha=0.95, edgecolor=\"0.5\", boxstyle=\"round,pad=0.25\"))\n",
    "\n",
    "        # --- compute zoom window from percentiles (like your code) ---\n",
    "        p_lo, p_hi = pct_window\n",
    "        x_lo, x_hi = np.nanpercentile(x, [p_lo, p_hi])\n",
    "        y_lo, y_hi = np.nanpercentile(y, [p_lo, p_hi])\n",
    "        pad_x = 0.03 * (x_hi - x_lo) if x_hi > x_lo else 1.0\n",
    "        pad_y = 0.03 * (y_hi - y_lo) if y_hi > y_lo else 1.0\n",
    "        zx0, zx1 = x_lo - pad_x, x_hi + pad_x\n",
    "        zy0, zy1 = y_lo - pad_y, y_hi + pad_y\n",
    "\n",
    "        # --- INSET axes (same as your pattern) ---\n",
    "        axins = inset_axes(ax, width=inset_size[0], height=inset_size[1],\n",
    "                           loc=inset_loc, borderpad=1.0)\n",
    "        axins.set_facecolor((1, 1, 1, 0.90))\n",
    "        axins.set_zorder(3)\n",
    "\n",
    "        # inset scatter\n",
    "        axins.scatter(x, y, s=6, alpha=scatter_kwargs.get(\"alpha\", 0.9),\n",
    "                      c=scatter_kwargs.get(\"c\", \"tab:blue\"), edgecolor=\"none\")\n",
    "        axins.set_xlim(zx0, zx1)\n",
    "        axins.set_ylim(zy0, zy1)\n",
    "        axins.axvline(0, color=\"k\", lw=1, alpha=0.9)\n",
    "        axins.set_xlabel(\"xtrk_dist\", fontsize=8)\n",
    "        axins.set_ylabel(\"width\", fontsize=8)\n",
    "        axins.tick_params(axis=\"both\", labelsize=7)\n",
    "        axins.set_title(\"zoom + trends\", fontsize=8, pad=2)\n",
    "\n",
    "        # dashed trend lines (x<0, x>0) inside inset, clipped to zoom\n",
    "        for xmask in (x < 0, x > 0):\n",
    "            xs, ys = x[xmask], y[xmask]\n",
    "            fit = _fit_line(xs, ys)\n",
    "            if fit is None:\n",
    "                continue\n",
    "            slope, intercept, xlo_side, xhi_side = fit\n",
    "            lo = max(min(xlo_side, xhi_side), zx0)\n",
    "            hi = min(max(xlo_side, xhi_side), zx1)\n",
    "            if hi > lo:\n",
    "                xf = np.linspace(lo, hi, 200)\n",
    "                axins.plot(xf, slope*xf + intercept, linestyle=\"--\", linewidth=1.5, color=\"red\")\n",
    "\n",
    "        # connectors (STRONG alpha as you wanted)\n",
    "        try:\n",
    "            mark_inset(ax, axins, loc1=connectors[0], loc2=connectors[1],\n",
    "                       fc=\"none\", ec=\"crimson\", lw=1.2, alpha=0.2)\n",
    "        except Exception:\n",
    "            import matplotlib.patches as patches\n",
    "            rect = patches.Rectangle((zx0, zy0), zx1 - zx0, zy1 - zy0,\n",
    "                                     fill=False, ec=\"crimson\", lw=1.2, alpha=0.2)\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "        last_ax = i\n",
    "\n",
    "    # hide unused axes\n",
    "    for j in range(last_ax + 1, len(axes)):\n",
    "        axes[j].set_visible(False)\n",
    "\n",
    "    fig.suptitle(f\"{river} — 25% sampled (r, ρ in panel)\", fontsize=14, y=0.995)\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c6efeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nodes_grid_with_inset(PAIRS, \"Sacramento\",  y_max=1000,  pct_window=(2, 100),inset_loc=\"upper center\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hypsometry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
